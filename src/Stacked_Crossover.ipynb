{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from vecstack import stacking\n",
    "from lucrum.algo import pyta\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import lucrum.datareader.dataconst as dcons\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from lucrum.algo.stackedclf import StackedClf, SklearnHelper\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier,\n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>close_time</th>\n",
       "      <th>trades</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-05 02:00:00+02:00</td>\n",
       "      <td>0.88980</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>0.88800</td>\n",
       "      <td>0.89766</td>\n",
       "      <td>2018-05-05 02:14:59.999000+02:00</td>\n",
       "      <td>274</td>\n",
       "      <td>159373.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-05 02:15:00+02:00</td>\n",
       "      <td>0.89766</td>\n",
       "      <td>0.90460</td>\n",
       "      <td>0.89601</td>\n",
       "      <td>0.90388</td>\n",
       "      <td>2018-05-05 02:29:59.999000+02:00</td>\n",
       "      <td>290</td>\n",
       "      <td>243422.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-05 02:30:00+02:00</td>\n",
       "      <td>0.90388</td>\n",
       "      <td>0.90460</td>\n",
       "      <td>0.89540</td>\n",
       "      <td>0.90391</td>\n",
       "      <td>2018-05-05 02:44:59.999000+02:00</td>\n",
       "      <td>206</td>\n",
       "      <td>126523.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-05 02:45:00+02:00</td>\n",
       "      <td>0.90390</td>\n",
       "      <td>0.90500</td>\n",
       "      <td>0.89520</td>\n",
       "      <td>0.89644</td>\n",
       "      <td>2018-05-05 02:59:59.999000+02:00</td>\n",
       "      <td>295</td>\n",
       "      <td>121757.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-05 03:00:00+02:00</td>\n",
       "      <td>0.89643</td>\n",
       "      <td>0.89922</td>\n",
       "      <td>0.89218</td>\n",
       "      <td>0.89470</td>\n",
       "      <td>2018-05-05 03:14:59.999000+02:00</td>\n",
       "      <td>251</td>\n",
       "      <td>146653.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   open_time     open     high      low    close  \\\n",
       "0  2018-05-05 02:00:00+02:00  0.88980  0.90000  0.88800  0.89766   \n",
       "1  2018-05-05 02:15:00+02:00  0.89766  0.90460  0.89601  0.90388   \n",
       "2  2018-05-05 02:30:00+02:00  0.90388  0.90460  0.89540  0.90391   \n",
       "3  2018-05-05 02:45:00+02:00  0.90390  0.90500  0.89520  0.89644   \n",
       "4  2018-05-05 03:00:00+02:00  0.89643  0.89922  0.89218  0.89470   \n",
       "\n",
       "                         close_time  trades     volume  \n",
       "0  2018-05-05 02:14:59.999000+02:00     274  159373.17  \n",
       "1  2018-05-05 02:29:59.999000+02:00     290  243422.10  \n",
       "2  2018-05-05 02:44:59.999000+02:00     206  126523.80  \n",
       "3  2018-05-05 02:59:59.999000+02:00     295  121757.09  \n",
       "4  2018-05-05 03:14:59.999000+02:00     251  146653.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load dataset \n",
    "load_data = pd.read_csv('dataxrp.csv', sep='\\t', dtype={\"open\": float})\n",
    "load_data.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "display(load_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# generating features\n",
    "\n",
    "# take a copy of the original dataset \n",
    "# so to work with another dataframe \n",
    "df = load_data.copy()\n",
    "\n",
    "# seed to reproduce results\n",
    "seed=56\n",
    "\n",
    "# moving average parameters \n",
    "lead_ma = \"ema\"\n",
    "lag_ma = \"sma\"\n",
    "\n",
    "# hyperparameters\n",
    "lead_timeperiod = 5\n",
    "lag_timeperiod = 8\n",
    "lag_delay = 6\n",
    "crossover_distance = 1\n",
    "\n",
    "# generate crossover indicators \n",
    "pyta.crossover(data=df,\n",
    "               indicator_a=lead_ma,\n",
    "               indicator_a_time=lead_timeperiod,\n",
    "               indicator_b=lag_ma,\n",
    "               indicator_b_time=lag_timeperiod)\n",
    "\n",
    "# now generate lagged moving average indicators \n",
    "# for lead moving average\n",
    "lead_ma_col = lead_ma + str(lead_timeperiod)\n",
    "\n",
    "# keep reference to moving average column names\n",
    "ma_cols = [lead_ma_col]\n",
    "ma_cols += pyta.lag_col(data=df,\n",
    "                        lag=lag_delay,\n",
    "                        col=lead_ma_col,\n",
    "                        loc_offset=1)\n",
    "\n",
    "# for lag moving avergae \n",
    "lag_ma_col = lag_ma + str(lag_timeperiod)\n",
    "ma_cols.append(lag_ma_col)\n",
    "ma_cols += pyta.lag_col(data=df,\n",
    "                        lag=lag_delay,\n",
    "                        col=lag_ma_col,\n",
    "                        loc_offset=1)\n",
    "\n",
    "# now we normalize all moving average values to 0..1\n",
    "df[ma_cols] = df[ma_cols].div(df[ma_cols].sum(axis=1), axis=0)\n",
    "\n",
    "# keep reference to difference column names\n",
    "# as they will be used as features to train our model\n",
    "ma_diff_cols = []\n",
    "\n",
    "# feature reduction subtract pairs (lag-lead/sma-ema)\n",
    "for i in range(0, lag_delay + 1):\n",
    "    \n",
    "    # get current column name depending on index\n",
    "    tmp_lag_col = lag_ma_col if i==0 else lag_ma_col + \"_lag_\" + str(i)\n",
    "    tmp_lead_col = lead_ma_col if i==0 else lead_ma_col + \"_lag_\" + str(i)\n",
    "    \n",
    "    # calculate differences & insert\n",
    "    ma_diff = df[tmp_lag_col] - df[tmp_lead_col]\n",
    "    tmp_col = \"ma_\" + str(i)\n",
    "    df.insert(df.shape[1] - 1, tmp_col, ma_diff)\n",
    "    ma_diff_cols.append(tmp_col)\n",
    "\n",
    "# shift crossover/outcome since we want to train model to classify crossover\n",
    "# fill empty with -1 to convert to int\n",
    "crossover = df[\"crossover\"].shift(-crossover_distance).fillna(-1).astype(int).copy()\n",
    "df[\"crossover\"] = crossover\n",
    "df.drop(df.tail(crossover_distance).index, inplace=True) # remove the rows filled with crossover as -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# splitting data for training and test \n",
    "def train_test_split_ts(data, test_size):\n",
    "    total_samples = data.shape[0]\n",
    "    test_samples = int(total_samples * test_size)\n",
    "    training_samples = total_samples - test_samples\n",
    "    return data.head(training_samples).copy(), data.tail(test_samples).copy()\n",
    "\n",
    "# split into training and test \n",
    "test_size = 0.30\n",
    "df_training, df_test = train_test_split_ts(data=df,\n",
    "                                           test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    19721\n",
      "1     3552\n",
      "Name: crossover, dtype: int64\n",
      "0    8443\n",
      "1    1530\n",
      "Name: crossover, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# to train the crossover prediction model we need to check \n",
    "# for class imbalance in the training dataset \n",
    "print(df_training[\"crossover\"].value_counts())\n",
    "print(df_test[\"crossover\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# split data \n",
    "# training dataset\n",
    "X_train = df_training[ma_diff_cols]\n",
    "y_train = df_training[\"crossover\"]\n",
    "\n",
    "# oversample training dataset -> I think oversampling requires different steps \n",
    "# eg: try before pre processing stuff \n",
    "# X_train_os, y_train_os = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "# test dataset\n",
    "X_test = df_test[ma_diff_cols]\n",
    "y_test = df_test[\"crossover\"]\n",
    "\n",
    "# display(df_training)\n",
    "# display(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7128205128205128\n",
      "Counter({0: 9388, 1: 585})\n",
      "0.7019667170953101\n",
      "Counter({0: 9312, 1: 661})\n",
      "0.6062917063870352\n",
      "Counter({0: 8924, 1: 1049})\n",
      "0.6465781409601634\n",
      "Counter({0: 8994, 1: 979})\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1,\n",
    "                           n_estimators=100,\n",
    "                           criterion=\"gini\",\n",
    "                           max_depth=15,\n",
    "                           min_samples_leaf=1,\n",
    "                           max_features=\"sqrt\").fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "score = precision_score(y_test, y_pred, pos_label=1, average=\"binary\")\n",
    "print(score)\n",
    "print(collections.Counter(y_pred))\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100,\n",
    "                           max_depth=5,\n",
    "                           min_samples_leaf=1,\n",
    "                           max_features=\"sqrt\").fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "score = precision_score(y_test, y_pred, pos_label=1, average=\"binary\")\n",
    "print(score)\n",
    "print(collections.Counter(y_pred))\n",
    "\n",
    "clf = xgb.XGBClassifier(random_state=0, \n",
    "                        n_jobs=-1, \n",
    "                      learning_rate=0.3, \n",
    "                      n_estimators=100, \n",
    "                      max_depth=10).fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "score = precision_score(y_test, y_pred, pos_label=1, average=\"binary\")\n",
    "print(score)\n",
    "print(collections.Counter(y_pred))\n",
    "\n",
    "clf = LGBMClassifier(random_state=0, \n",
    "                     n_jobs=-1, \n",
    "                     learning_rate=0.2, \n",
    "                     n_estimators=100, \n",
    "                     max_depth=15).fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "score = precision_score(y_test, y_pred, pos_label=1, average=\"binary\")\n",
    "print(score)\n",
    "print(collections.Counter(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [log_loss]\n",
      "mode:         [oof_pred]\n",
      "n_models:     [4]\n",
      "\n",
      "model  0:     [RandomForestClassifier]\n",
      "    fold  0:  [0.28638152]\n",
      "    fold  1:  [0.28870036]\n",
      "    fold  2:  [0.29040325]\n",
      "    fold  3:  [0.29567340]\n",
      "    fold  4:  [0.30792970]\n",
      "    ----\n",
      "    MEAN:     [0.29381765] + [0.00769070]\n",
      "    FULL:     [0.29381679]\n",
      "\n",
      "    Fitting on full train set...\n",
      "\n",
      "model  1:     [XGBClassifier]\n",
      "    fold  0:  [0.32149345]\n",
      "    fold  1:  [0.30734637]\n",
      "    fold  2:  [0.33579404]\n",
      "    fold  3:  [0.32396978]\n",
      "    fold  4:  [0.35347263]\n",
      "    ----\n",
      "    MEAN:     [0.32841525] + [0.01545244]\n",
      "    FULL:     [0.32841375]\n",
      "\n",
      "    Fitting on full train set...\n",
      "\n",
      "model  2:     [LGBMClassifier]\n",
      "    fold  0:  [0.28500545]\n",
      "    fold  1:  [0.28296854]\n",
      "    fold  2:  [0.29903503]\n",
      "    fold  3:  [0.29739868]\n",
      "    fold  4:  [0.30776734]\n",
      "    ----\n",
      "    MEAN:     [0.29443501] + [0.00925301]\n",
      "    FULL:     [0.29443370]\n",
      "\n",
      "    Fitting on full train set...\n",
      "\n",
      "model  3:     [GradientBoostingClassifier]\n",
      "    fold  0:  [0.28168480]\n",
      "    fold  1:  [0.28695132]\n",
      "    fold  2:  [0.28711238]\n",
      "    fold  3:  [0.29394326]\n",
      "    fold  4:  [0.29293161]\n",
      "    ----\n",
      "    MEAN:     [0.28852467] + [0.00447294]\n",
      "    FULL:     [0.28852402]\n",
      "\n",
      "    Fitting on full train set...\n",
      "\n",
      "0.6913907284768211\n",
      "Counter({0: 9218, 1: 755})\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(n_jobs=-1,\n",
    "                           n_estimators=100,\n",
    "                           criterion=\"gini\",\n",
    "                           max_depth=15,\n",
    "                           min_samples_leaf=1,\n",
    "                           max_features=\"sqrt\"),\n",
    "    \n",
    "    xgb.XGBClassifier(random_state=0, \n",
    "                      n_jobs=-1, \n",
    "                      learning_rate=0.3, \n",
    "                      n_estimators=100, \n",
    "                      max_depth=10),\n",
    "    \n",
    "    LGBMClassifier(random_state=0, \n",
    "                     n_jobs=-1, \n",
    "                     learning_rate=0.2, \n",
    "                     n_estimators=100, \n",
    "                     max_depth=15),\n",
    "    \n",
    "    GradientBoostingClassifier(n_estimators=200,\n",
    "                           max_depth=3,\n",
    "                           min_samples_leaf=1,\n",
    "                           max_features=\"sqrt\")\n",
    "]\n",
    "\n",
    "S_train, S_test = stacking(models, \n",
    "                           X_train, \n",
    "                           y_train, \n",
    "                           X_test,   \n",
    "                           regression=False, \n",
    "                           mode='oof_pred', \n",
    "                           save_dir=None, \n",
    "                           #metric=precision_score, \n",
    "                           n_folds=5, \n",
    "                           stratified=True,\n",
    "                           shuffle=False,  \n",
    "                           needs_proba=True,\n",
    "                           verbose=2)\n",
    "\n",
    "meta_model = LogisticRegression(penalty=\"l2\",\n",
    "                                solver=\"lbfgs\",\n",
    "                                max_iter=1000,\n",
    "                                n_jobs=-1).fit(S_train, y_train)\n",
    "\n",
    "y_pred = meta_model.predict(S_test)\n",
    "score = precision_score(y_test, y_pred, pos_label=1, average=\"binary\")\n",
    "print(score)\n",
    "print(collections.Counter(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ari5123] *",
   "language": "python",
   "name": "conda-env-ari5123-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
